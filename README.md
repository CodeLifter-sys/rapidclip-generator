# **RapidClip**

**RapidClip** is a project that automates the creation of short videos, ideal for platforms like YouTube Shorts, Instagram Reels, TikTok, and Kwai. It allows generating complete videos from a given theme, combining narration, dynamic images, visual effects, synchronized subtitles, detailed process logging, background music integration, automatic volume balancing of background music in harmony with narration, and final video assembly and rendering with animated transitions. By using OpenAI's new TTS models (Recommended), the application can dynamically define the tone used in narration, intonation, and other voice characteristics.

üáßüá∑ For the Portuguese (pt-br) version of this README, see [README.pt-br.md](README.pt-br.md).

---

## **Demonstration Videos Generated by RapidClip:**
_Note: The demonstration videos were converted from mp4 to mov._

<table>
  <thead>
    <tr>
      <th align="center"><g-emoji alias="arrow_forward">‚ñ∂Ô∏è</g-emoji> Demo 1</th>
      <th align="center"><g-emoji alias="arrow_forward">‚ñ∂Ô∏è</g-emoji> Demo 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">
        <video controls width="480">
          <source src="https://raw.githubusercontent.com/itallonardi/rapidclip-generator/main/demos/en/animal_life.mov" type="video/quicktime">
          Your browser does not support the video element. Download it.
        </video>
        <br>
        <a href="https://raw.githubusercontent.com/itallonardi/rapidclip-generator/main/demos/en/animal_life.mov" download>Download Demo 1</a>
      </td>
      <td align="center">
        <video controls width="480">
          <source src="https://raw.githubusercontent.com/itallonardi/rapidclip-generator/main/demos/en/history.mov" type="video/quicktime">
          Your browser does not support the video element. Download it.
        </video>
        <br>
        <a href="https://raw.githubusercontent.com/itallonardi/rapidclip-generator/main/demos/en/history.mov" download>Download Demo 2</a>
      </td>
    </tr>
  </tbody>
</table>

---

## **Implemented Features**

- **Automatic Content Creation**: Generates custom scripts based on the provided theme.
- **Audio Narration**: Converts scripts into high-quality narration, supporting both ElevenLabs and OpenAI TTS.
- **Audio Reprocessing**: Adjusts audio duration for platform compatibility.
- **Subtitle Generation**: Creates enhanced subtitles with alignment and segmentation:
  - Tokenization of transcribed text while preserving punctuation.
  - Word alignment with respective timestamps and punctuation.
  - Readable and synchronized subtitles, respecting character and word limits per line.
- **Enhanced Image Generation**:
  - Diverse prompt generation for image creation using subtitle context and generated prompts to ensure variation and creativity.
  - Support for configuring the SANA model version via an environment variable.
- **Final Video Assembly**: Composes the final video using audio, images, subtitles, and animated transitions (including zoom-in effect) while maintaining a resolution of 1080x1920.
- **Background Music Integration**:
  - Selects a soundtrack from a local library of royalty-free music (configured in `songs/songs.json` and stored in `songs/mp3`).
  - Automatic music selection by an AI model based on the script and generated images.
- **Relevant Images**: Improves image selection to better illustrate content.
- **Visual Effects and Transitions**: Applies zoom, animations, and additional smooth cuts.
- **Complete Rendering**: Creates the final video ready for publishing.
- **Multi-Language Support**: Enables content creation, narration, and subtitles in various languages.
- **Process Logging**: Stores detailed logs of the process, including generated prompts for each image interval, in the output folder of each video.
- **Support for OpenAI's New TTS Models**: By using OpenAI's new TTS models, the application dynamically defines narration tone, intonation, and other voice characteristics.

---

## **How to Use RapidClip**

Before using RapidClip, you need to configure environment variables. Use the `.env.example` file as a template to create your own `.env` file containing the following variables:

```plaintext
OPENAI_API_KEY=your-openai-api-key
ELEVENLABS_API_KEY=your-elevenlabs-api-key
REPLICATE_API_TOKEN=your-replicate-api-key
SANA_MODEL_VERSION=sana-model-version
```

---

## **Running RapidClip**

### **Using Docker**

You can run RapidClip via Docker, simplifying usage in an isolated environment with all dependencies pre-installed. For more details, check [README.DOCKER.md](README.DOCKER.md).

### **Local Execution (Without Docker)**

If you prefer to run the project directly on your machine, follow these steps:

**1. Install dependencies:**

```bash
pip install -r requirements.txt
```

**2. Generate the video:**

**Using OpenAI TTS (Recommended!):**
```bash
python src/main.py --theme "Technology Curiosities (a single curiosity)" \
  --language "en-US" \
  --max_duration 60 \
  --tts_service openai \
  --openai_tts_model "gpt-4o-mini-tts" \
  --openai_tts_voice "ash"
```

**Using ElevenLabs TTS:**
```bash
python src/main.py --theme "Space Curiosities (a single curiosity)" \
  --language "en-US" \
  --voice_id "CstacWqMhJQlnfLPxRG4" \
  --max_duration 60 \
  --tts_service elevenlabs
```

---

## **Next Steps**

1. Refine advanced video editing features for more sophisticated functionalities.

---

## **Contributions**

We welcome contributions! If you would like to collaborate with the project, follow these steps:

1. Fork the repository.
2. Create a branch for your feature or bug fix:
   ```bash
   git checkout -b my-contribution
   ```
3. Make your changes and submit a pull request detailing your modifications.

---

## **License**

This project is licensed under the **MIT** license. This means you can use, modify, and distribute it as long as the original license is included in the code. See the [LICENSE](LICENSE) file for more details.
